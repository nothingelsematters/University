+ A [Cross-validation](#A)
+ B [F-score](#B)
+ C [Nonparametric regression](#C)
+ D [Linear regression](#D)
+ E [Support-vector machine](#E)
+ F [Наивный байесовский классификатор](#F)
+ G [Дерево принятия решений](#G)

<a name="A"></a>
## [A. Перекрёстная проверка](cross-validation.cpp)
<p align="left"><i><br>
ограничение по времени на тест: 1 секунда<br>
ограничение по памяти на тест: 256 мегабайт<br>
ввод: стандартный ввод<br>
вывод: стандартный вывод</i></p>

__Условие:__
Разбейте множество из $N$ объектов, каждый из которых принадлежит к одному из $M$ классов, на $K$ частей. Каждый объект должен попасть ровно в одну часть так, чтобы размеры частей, а также распределение классов по этим частям было сбалансировано. Формально, пусть $cnt(x,c)$ — число объектов с классом $c$ попавших в часть $x$, тогда должно выполняться $\forall x,y,c : \left | cnt(x,c) - cnt(y,c) \right | \leq 1$ и $\forall x,y : \left | \sum_c cnt(x,c) - \sum_c cnt(y,c) \right | \leq 1$.

__Входные данные:__
Первая строка: три целых числа $N$, $M$, $K$ ($1 \leq N \leq 10^5$, $1 \leq M,K \leq N$) — число объектов, классов и частей.

__Выходные данные:__
Выведите $K$ строк. Каждая строка $x$ начинается с целого числа $S$ — размера части $x$. Далее идут $S$ целых чисел — номера объектов попавших в часть $x$. Объекты нумеруются с единицы.

__Пример__
>__Входные данные__
10 4 3
1 2 3 4 1 2 3 1 2 1
__Выходные данные__
4 1 4 9 10
3 2 3 5
3 6 7 8


***

<a name="B"></a>
## [B. F-мера](f-score.cpp)
<p align="left"><i><br>
ограничение по времени на тест: 1 секунда<br>
ограничение по памяти на тест: 256 мегабайт<br>
ввод: стандартный ввод<br>
вывод: стандартный вывод</i></p>

__Условие:__
В результате эксперимента по классификации на $K$ классов была получена матрица неточностей (Confusion matrix) $CM$, где $CM[c,t]$ — число объектов класса $c$, которые были классифицированы как $t$. Посчитайте по данной матрице неточностей средневзвешенную по классам макро и микро F-меру.

__Входные данные:__
Первая строка содержит целое число $K$ — число классов ($1 \leq K \leq 20$). Далее идёт $K$ строк — описание матрицы неточностей. Каждая строка $c$ содержит $K$ целых чисел — $c$-тая строка матрицы неточностей. $\forall c,t : 0 \leq CM[c,t] \leq 100$ и $\exists c,t : CM[c,t] \geq 1$.

__Выходные данные:__
Выведите два вещественных числа с плавающей точкой — взвешенно усреднённую по классам макро и микро F-меру. Абсолютная погрешность ответа не должна превышать $10^{-6}$.

__Пример__
>__Входные данные__
2
0 1
1 3
__Выходные данные__
0.6
0.6

>__Входные данные__
3
3 1 1
3 1 1
1 3 1
__Выходные данные__
0.326860841
0.316666667


***

<a name="C"></a>
## C. Непараметрическая регрессия
<p align="left"><i><br>
ограничение по времени на тест: 2 секунды<br>
ограничение по памяти на тест: 256 мегабайт<br>
ввод: стандартный ввод<br>
вывод: стандартный вывод</i></p>

__Условие:__
Реализуйте алгоритм непараметрической регрессии, который бы поддерживал различные функции расстояний, ядер и окон. Описание ядер можно найти здесь: https://en.wikipedia.org/w/index.php?oldid=911077090

__Входные данные:__
Первая строка содержит два целых числа $N$ и $M$ — число объектов и признаков ($1 \leq N \leq 100$, $1 \leq M \leq 10$).

__Выходные данные:__
Выведите одно вещественное число с плавающей точкой — результат запроса.

__Пример__
>__Входные данные__
3 2
0 2 1
1 1 0
2 0 1
0 0
euclidean
uniform
fixed
2
__Выходные данные__
0.0000000000

>__Входные данные__
3 2
0 2 1
1 1 0
2 0 1
0 0
euclidean
gaussian
variable
2
__Выходные данные__
0.6090086848


***

<a name="D"></a>
## D. Линейная регрессия
<p align="left"><i><br>
ограничение по времени на тест: 0.75 секунд<br>
ограничение по памяти на тест: 256 мегабайт<br>
ввод: стандартный ввод<br>
вывод: стандартный вывод</i></p>

__Условие:__
Найдите уравнения прямой аппроксимирующей положение объектов из заданного набора данных.

__Входные данные:__
Первая строка содержит два целых числа $N$ ($1 \leq N \leq 10^4$) — число объектов в обучающем множестве, и $M$ ($1 \leq M \leq \min (N, 1000)$) — число признаков у объектов исключая зависимую переменную.

__Выходные данные:__
Выведите $M + 1$ вещественных чисел с плавающей точкой $A_j$ — коэффициенты прямой из уравнения $Y = A_0 \cdot X_0 + A_1 \cdot X_1 + \dots + A_{M-1} \cdot X_{M-1} + A_M$

__Пример__

***

<a name="E"></a>
## E. Метод опорных векторов
<p align="left"><i><br>
ограничение по времени на тест: 1 секунда<br>
ограничение по памяти на тест: 256 мегабайт<br>
ввод: стандартный ввод<br>
вывод: стандартный вывод</i></p>

__Условие:__
Найдите коэффициенты $\lambda_i$ опорных векторов и сдвиг $b$, для классификации по формуле $class(x) = sign(\sum_i y_i \cdot \lambda_i \cdot k(x, x_i) + b)$, где $x$ — это векторное описание запрашиваемого объекта, а $k$ — функция ядра.

__Входные данные:__
В первой строке находится целое число $N$ ($1 \leq N \leq 100$) — число объектов в обучающем множестве.

__Выходные данные:__
Выведите $N+1$ число с плавающей точкой: первые $N$ чисел — коэффициенты $\lambda_i$ ($0 \leq \lambda_i \leq C$, $\sum \lambda_i \cdot Y_i = 0$) соответствующие объектам из тренировочного множества, последнее число $b$ ($\left | b \right | \leq 10^{12}$) — коэффициент сдвига.

__Пример__

***

<a name="F"></a>
## F. Наивный байесовский классификатор
<p align="left"><i><br>
ограничение по времени на тест: 1 секунда<br>
ограничение по памяти на тест: 256 мегабайт<br>
ввод: стандартный ввод<br>
вывод: стандартный вывод</i></p>

__Условие:__
Реализуйте оптимальный наивный байесовский классификатор.Априорные вероятности классов оцениваются обыкновенным частотным методом.Вероятности встречи отдельных слов в каждом классе оцениваются с использованием аддитивного сглаживания (сглаживание Лапласа) https://en.wikipedia.org/wiki/Additive_smoothing Словари для каждого класса вычисляются независимо.

__Входные данные:__
В первой строке содержится целое положительное число $K$ ($1 \leq K \leq 10$) — число классов.

__Выходные данные:__
Выведите $M$ строк — результаты мягкой классификации оптимального наивного байесовского классификатора соответствующих сообщений из проверочной выборки.

__Пример__
>__Входные данные__
3
1 1 1
1
3
1 4 a b c d
2 3 a b c
3 2 a b
4
1 a
2 a b
3 a b c
1 f
__Выходные данные__
0.2553191489 0.3191489362 0.4255319149
0.1872561769 0.2925877763 0.5201560468
0.1898275294 0.3707568933 0.4394155773
0.2553191489 0.3191489362 0.4255319149


***

<a name="G"></a>
## G. Дерево принятия решений
<p align="left"><i><br>
ограничение по времени на тест: 1.5 секунд<br>
ограничение по памяти на тест: 256 мегабайт<br>
ввод: стандартный ввод<br>
вывод: стандартный вывод</i></p>

__Условие:__
Постройте дерево принятия решений.

__Входные данные:__
Первая строка содержит три целых положительных числа $M$ ($1 \leq M \leq 100$) — число признаков у объектов (исключая класс), $K$ ($1 \leq K \leq 20$) — число классов и $H$ ($1 \leq H \leq 10$) — максимальная глубина (в рёбрах) дерева принятия решений.

__Выходные данные:__
Выведите построенное дерево принятия решений.
